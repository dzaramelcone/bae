---
phase: 27-graph-mode
plan: 04
type: execute
wave: 1
depends_on: []
files_modified:
  - bae/lm.py
  - bae/graph.py
  - bae/repl/engine.py
  - tests/repl/test_engine.py
  - tests/test_graph.py
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "Graph runs complete without premature timeout on complex graphs (6+ nodes)"
    - "inspect shows node trace even when a graph fails mid-execution"
    - "trace shows node transition history even when a graph fails mid-execution"
    - "graph() callable accepts flattened simple params (e.g. name, city) instead of requiring constructed BaseModel objects"
  artifacts:
    - path: "bae/lm.py"
      provides: "Increased per-call timeout"
      contains: "timeout: int = 120"
    - path: "bae/graph.py"
      provides: "Flattened params + partial trace attached to all exceptions from arun()"
      contains: "_composites"
    - path: "bae/repl/engine.py"
      provides: "_wrap_coro extracts partial trace from failed coroutine exceptions"
      contains: "hasattr.*trace"
  key_links:
    - from: "bae/graph.py"
      to: "exception.trace"
      via: "top-level try/except in arun attaches trace to any unhandled exception"
      pattern: "except Exception.*trace"
    - from: "bae/repl/engine.py"
      to: "run.result"
      via: "_wrap_coro reads exception.trace on failure and populates run.result"
      pattern: "run\\.result.*GraphResult"
---

<objective>
Fix graph execution pipeline: increase LM timeout, preserve partial trace on failure, surface trace data for failed runs, and flatten graph() callable signatures so users pass simple types instead of constructed BaseModel objects.

Purpose: UAT revealed timeouts, missing trace data on failure, and leaky abstraction requiring users to construct internal types. The graph() callable should accept flat kwargs (name, city, user_message) and reconstruct complex objects internally.
Output: Graphs complete reliably; failed runs expose partial trace; graph callables accept simple params.
</objective>

<execution_context>
@/Users/dzaramelcone/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dzaramelcone/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/27-graph-mode/27-01-SUMMARY.md
@.planning/phases/27-graph-mode/27-02-SUMMARY.md
@.planning/debug/graph-run-timeout-no-trace.md
@bae/lm.py
@bae/graph.py
@bae/repl/engine.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Increase LM timeout and attach partial trace to all arun exceptions</name>
  <files>bae/lm.py, bae/graph.py, tests/test_graph.py</files>
  <action>
Two changes:

**bae/lm.py** (line 413): Change `timeout: int = 20` to `timeout: int = 120` in ClaudeCLIBackend.__init__. 120s is generous for a single LM call while still protecting against hangs.

**bae/graph.py** `arun()` method: Wrap the `while current is not None:` loop body in a try/except that catches any Exception not already carrying a `.trace` attribute, attaches the current `trace` list, and re-raises. This ensures RuntimeError from LM timeout (which graph.py doesn't currently catch) carries the partial trace just like BaeError and DepError already do.

The catch must:
- NOT catch `asyncio.CancelledError` (it's BaseException in 3.9+, but be explicit)
- Check `if not hasattr(e, 'trace')` before attaching (BaeError/DepError already have it)
- Set `e.trace = trace` then `raise`
- Go around the ENTIRE while loop (not inside it) so it captures trace accumulated across all iterations

Place the try/except like:
```python
trace: list[Node] = []
...
try:
    while current is not None:
        ...existing loop body unchanged...
except Exception as e:
    if not hasattr(e, "trace"):
        e.trace = trace
    raise
```

This is minimal -- the existing BaeError/DepError catches inside the loop still work, they set .trace and raise, and our outer catch sees .trace already set and doesn't overwrite.

**tests/test_graph.py**: Add a test that verifies a RuntimeError raised during graph execution carries a `.trace` attribute with the partial trace. Create a MockLM that succeeds for the first N fill calls then raises RuntimeError. Run the graph with it, catch the RuntimeError, and assert `.trace` is a list with the nodes that executed before the error.
  </action>
  <verify>`uv run pytest tests/test_graph.py -x -q` passes with zero warnings. New test confirms RuntimeError from LM carries `.trace` attribute.</verify>
  <done>ClaudeCLIBackend.timeout is 120. Any exception from arun() carries .trace with the partial execution history.</done>
</task>

<task type="auto">
  <name>Task 2: Extract partial trace from failed coroutine in engine _wrap_coro</name>
  <files>bae/repl/engine.py, tests/repl/test_engine.py</files>
  <action>
In `_wrap_coro` (engine.py), the `except Exception as e:` block (line 154-156) currently only sets `run.state` and `run.error`. It needs to also extract partial trace from the exception and populate `run.result` so that `inspect` and `trace` commands can display data for failed runs.

Modify the except clause in `_wrap_coro`:
```python
except Exception as e:
    run.state = GraphState.FAILED
    run.error = f"{type(e).__name__}: {e}"
    # Preserve partial trace from graph execution for inspect/trace commands
    if hasattr(e, "trace"):
        from bae.result import GraphResult
        run.result = GraphResult(node=None, trace=e.trace)
    raise
```

The `from bae.result import GraphResult` import is inside the except block to keep it lazy (matching existing pattern in engine.py where Graph import is TYPE_CHECKING only). GraphResult(node=None, trace=...) matches what arun() returns on success.

Also apply the same pattern to `_execute`'s except clause (line 117-119) for consistency -- _execute already has TimingLM but if graph.arun raises with a .trace, we should still capture it:
```python
except Exception as e:
    run.state = GraphState.FAILED
    run.error = f"{type(e).__name__}: {e}"
    if hasattr(e, "trace"):
        from bae.result import GraphResult
        run.result = GraphResult(node=None, trace=e.trace)
    raise
```

**tests/repl/test_engine.py**: Add tests:
1. `test_wrap_coro_preserves_trace_on_failure`: Create a coroutine that raises an exception with `.trace = [node1, node2]` attribute set. Submit via submit_coro. After task completes, verify `run.result is not None` and `run.result.trace == [node1, node2]`.
2. `test_execute_preserves_trace_on_failure`: Similar for the _execute path -- mock graph.arun to raise BaeError with .trace attached. Verify run.result is populated.
  </action>
  <verify>`uv run pytest tests/repl/test_engine.py -x -q` passes with zero warnings. Failed runs now have `run.result.trace` populated.</verify>
  <done>_wrap_coro and _execute both extract .trace from exceptions and populate run.result, enabling inspect/trace commands to show data for failed graph runs.</done>
</task>

<task type="auto">
  <name>Task 3: Flatten BaseModel params in graph() callable and remove _param_types</name>
  <files>bae/graph.py, tests/test_graph.py</files>
  <action>
Rewrite `graph()` in bae/graph.py so that BaseModel input fields are flattened into simple params and the wrapper reconstructs them before calling arun().

**Current behavior**: `ootd(user_info=UserInfo(name="Dzara"), user_message="hi")` — user must construct UserInfo.
**Target behavior**: `ootd(name="Dzara", user_message="hi")` — wrapper constructs UserInfo internally.

Replace the signature-building and wrapper logic in `graph()`:

```python
def graph(start: type[Node]):
    from pydantic import BaseModel
    from pydantic.fields import PydanticUndefined

    g = Graph(start=start)

    # Map which input fields need BaseModel reconstruction
    # _composites: {original_field_name: (ModelClass, [sub_field_names])}
    _composites: dict[str, tuple[type, list[str]]] = {}
    params = []

    for name, fi in g._input_fields.items():
        ann = fi.annotation
        if isinstance(ann, type) and issubclass(ann, BaseModel):
            # Flatten this BaseModel's fields into the signature
            sub_fields = []
            for sub_name, sub_fi in ann.model_fields.items():
                default = (
                    sub_fi.default
                    if sub_fi.default is not PydanticUndefined
                    else inspect.Parameter.empty
                )
                params.append(inspect.Parameter(
                    sub_name,
                    kind=inspect.Parameter.KEYWORD_ONLY,
                    annotation=sub_fi.annotation,
                    default=default,
                ))
                sub_fields.append(sub_name)
            _composites[name] = (ann, sub_fields)
        else:
            # Simple type — keep as-is
            params.append(inspect.Parameter(
                name,
                kind=inspect.Parameter.KEYWORD_ONLY,
                annotation=fi.annotation,
            ))

    params.append(inspect.Parameter("lm", kind=inspect.Parameter.KEYWORD_ONLY, default=None))
    params.append(inspect.Parameter("dep_cache", kind=inspect.Parameter.KEYWORD_ONLY, default=None))

    async def wrapper(*, lm=None, dep_cache=None, **kwargs):
        # Reconstruct BaseModel objects from flat kwargs
        arun_kwargs = {}
        for orig_name, (model_cls, sub_fields) in _composites.items():
            model_kwargs = {f: kwargs.pop(f) for f in sub_fields if f in kwargs}
            arun_kwargs[orig_name] = model_cls(**model_kwargs)
        arun_kwargs.update(kwargs)
        return await g.arun(lm=lm, dep_cache=dep_cache, **arun_kwargs)

    wrapper.__signature__ = inspect.Signature(params)
    wrapper.__name__ = start.__name__
    wrapper.__doc__ = f"Run {start.__name__} graph."
    wrapper._name = start.__name__

    return wrapper
```

Key points:
- Remove `_param_types` entirely (no longer needed — types aren't injected)
- BaseModel fields with defaults keep their defaults in the signature
- `_composites` is captured by the closure — zero overhead at call time
- Simple-type fields pass through unchanged

**tests/test_graph.py**: Update `TestGraphFactory` tests:
- `test_graph_factory_signature`: Update to check flattened params. For a start node with `inp: TInput` where TInput has `value: str`, the signature should contain `value: str`, NOT `inp: TInput`.
- Add `test_graph_factory_flattened_call`: Call `wrapper(value="hello", lm=mock_lm)` and verify it works — the wrapper reconstructs TInput(value="hello") internally.
- Update `test_graph_factory_param_types`: Remove this test (or rename to verify _param_types no longer exists).
- Update `examples/ootd.py` __main__ block: change `ootd(user_info=UserInfo(), user_message="...")` to `ootd(name="Dzara", user_message="...")`.
  </action>
  <verify>`uv run pytest tests/test_graph.py -x -q` passes. `uv run python -c "import inspect; from examples.ootd import ootd; print(inspect.signature(ootd))"` shows `(*, name: str = 'Dzara', gender: str = 'woman', user_message: str, lm=None, dep_cache=None)`.</verify>
  <done>graph() produces flat-param callables. Users pass simple types, wrapper reconstructs BaseModel objects. _param_types removed.</done>
</task>

</tasks>

<verification>
1. `uv run pytest tests/test_graph.py tests/repl/test_engine.py -x -q` -- all pass
2. `uv run pytest tests/ -x -q --ignore=tests/test_integration.py` -- full suite passes
3. Grep confirms: `grep "timeout.*120" bae/lm.py` shows new default
4. Grep confirms: `grep -n "e.trace" bae/graph.py` shows outer catch in arun
5. Grep confirms: `grep -n "run.result.*GraphResult" bae/repl/engine.py` shows trace extraction in both _wrap_coro and _execute
</verification>

<success_criteria>
- ClaudeCLIBackend timeout increased from 20 to 120 seconds
- All exceptions from graph.arun() carry a .trace attribute with partial execution history
- Engine _wrap_coro and _execute extract .trace from exceptions and populate run.result
- inspect and trace commands can display data for failed graph runs (no code change needed -- they already check run.result.trace)
- All existing + new tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/27-graph-mode/27-04-SUMMARY.md`
</output>
