---
phase: 30-agent-core-extraction
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - bae/agent.py
  - tests/test_agent.py
autonomous: true

must_haves:
  truths:
    - "extract_executable returns (code, extra_count) from text containing <run> blocks"
    - "agent_loop sends prompt, extracts <run> blocks, executes code, feeds output back, and loops until no blocks remain"
    - "agent_loop respects max_iters limit"
    - "agent_loop handles execution errors gracefully (feeds traceback back as next prompt)"
    - "_agent_namespace returns a fresh dict with practical imports (json, re, os, pathlib)"
  artifacts:
    - path: "bae/agent.py"
      provides: "Core agent loop and helpers"
      exports: ["extract_executable", "agent_loop"]
    - path: "tests/test_agent.py"
      provides: "Unit tests for agent core"
      contains: "test_extract_executable"
  key_links:
    - from: "bae/agent.py"
      to: "bae/repl/exec.py"
      via: "async_exec import"
      pattern: "from bae\\.repl\\.exec import async_exec"
---

<objective>
Create `bae/agent.py` with the extracted eval loop core: `extract_executable()`, `agent_loop()`, `_agent_namespace()`, and `_cli_send()`.

Purpose: Decouple the multi-turn eval loop from REPL concerns so it can power both the REPL AI wrapper and the headless AgenticBackend.
Output: `bae/agent.py` with tested core functions.
</objective>

<execution_context>
@/Users/dzaramelcone/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dzaramelcone/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/30-agent-core-extraction/30-RESEARCH.md
@bae/repl/ai.py
@bae/repl/exec.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create bae/agent.py with core agent functions</name>
  <files>bae/agent.py, tests/test_agent.py</files>
  <action>
Create `bae/agent.py` with the following module-level functions:

1. **`extract_executable(text: str) -> tuple[str | None, int]`** -- Move `_EXEC_BLOCK_RE` regex and the static method body from `AI.extract_executable` in `bae/repl/ai.py`. Same logic: find all `<run>` blocks, return first code + count of extras.

2. **`agent_loop(prompt, *, send, namespace, max_iters=10) -> str`** -- Extract the `<run>` block handling from `AI.__call__` (lines 146-200 of ai.py), stripped of all REPL concerns. The function:
   - Calls `send(prompt)` to get initial response
   - Loops: extract `<run>` block via `extract_executable`, execute via `async_exec` from `bae/repl/exec.py`, build feedback string, call `send(feedback)`
   - Handles coroutine results from async_exec (await them, capture stdout)
   - On execution error: catches BaseException, formats traceback, feeds it back
   - Stops when: no code blocks found, or `(no output)` with 0 extra blocks, or max_iters reached
   - Returns final response text
   - Does NOT handle tool tags, router writes, labels, store, or session management

3. **`_agent_namespace() -> dict`** -- Returns a fresh namespace with practical imports for headless agent use: `__builtins__`, `json`, `re`, `os`, `pathlib.Path`. Do NOT include httpx (may not be installed as a dep).

4. **`_cli_send(prompt, *, model, session_id, call_count, timeout=60) -> str`** -- Async function that calls Claude CLI subprocess. On `call_count == 0`: uses `--session-id` + `--system-prompt` (a minimal agent prompt embedded as a module constant `_AGENT_SYSTEM_PROMPT`). On subsequent calls: uses `--resume`. Sanitizes env (strips CLAUDECODE). Returns response text. Raises RuntimeError on failure.

The `_AGENT_SYSTEM_PROMPT` constant should be a minimal string: "You are a research agent. Use Python code in <run> tags to gather information. Write working code that produces output."

Write tests in `tests/test_agent.py` using TDD (RED then GREEN):

- `test_extract_executable_single_block` -- one `<run>` block returns (code, 0)
- `test_extract_executable_multiple_blocks` -- returns first + count of extras
- `test_extract_executable_no_blocks` -- returns (None, 0)
- `test_agent_loop_no_code` -- mock send returns plain text, loop exits immediately, returns response
- `test_agent_loop_single_iteration` -- mock send returns `<run>print('hi')</run>` first, then plain text. Verify send called twice, final response returned.
- `test_agent_loop_max_iters` -- mock send always returns code blocks; verify loop stops at max_iters
- `test_agent_loop_execution_error` -- mock send returns code that raises; verify traceback fed back
- `test_agent_namespace_fresh` -- verify _agent_namespace returns dict with expected keys, no shared state between calls

All tests must use mock send functions (async callables), no real Claude CLI calls. Use `bae/repl/exec.py`'s `async_exec` for real execution in the namespace (it's fast, no subprocess).
  </action>
  <verify>uv run pytest tests/test_agent.py -x -q</verify>
  <done>All tests pass. bae/agent.py exports extract_executable and agent_loop. No REPL imports except async_exec.</done>
</task>

</tasks>

<verification>
- `uv run pytest tests/test_agent.py -x -q` -- all tests pass
- `uv run python -c "from bae.agent import extract_executable, agent_loop"` -- imports work
- `grep -c "router\|store\|label\|ChannelRouter\|SessionStore" bae/agent.py` -- returns 0 (no REPL coupling)
</verification>

<success_criteria>
bae/agent.py exists with extract_executable, agent_loop, _agent_namespace, _cli_send. All unit tests pass. No REPL-specific imports (router, store, channels, label).
</success_criteria>

<output>
After completion, create `.planning/phases/30-agent-core-extraction/30-01-SUMMARY.md`
</output>
