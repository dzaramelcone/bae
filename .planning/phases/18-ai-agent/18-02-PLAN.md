---
phase: 18-ai-agent
plan: 02
type: execute
wave: 2
depends_on: ["18-01"]
files_modified:
  - bae/repl/shell.py
  - tests/repl/test_ai_integration.py
autonomous: true
user_setup:
  - service: anthropic
    why: "pydantic-ai Agent requires ANTHROPIC_API_KEY for NL conversation"
    env_vars:
      - name: ANTHROPIC_API_KEY
        source: "Anthropic Console -> API Keys (https://console.anthropic.com/settings/keys)"

must_haves:
  truths:
    - "NL mode dispatches to await ai(text) instead of stub"
    - "ai object is in the namespace and callable from PY mode"
    - "AI errors display on [ai] channel without crashing the REPL"
    - "All AI output routes through [ai] channel and is persisted to session store"
  artifacts:
    - path: "bae/repl/shell.py"
      provides: "AI wiring in CortexShell -- ai object creation, namespace injection, NL dispatch"
      contains: "from bae.repl.ai import AI"
    - path: "tests/repl/test_ai_integration.py"
      provides: "Integration tests for AI wiring in shell"
      min_lines: 60
  key_links:
    - from: "bae/repl/shell.py"
      to: "bae/repl/ai.py"
      via: "AI construction in CortexShell.__init__"
      pattern: "AI\\(lm="
    - from: "bae/repl/shell.py"
      to: "bae/repl/ai.py"
      via: "NL mode dispatch in run() loop"
      pattern: "await self\\.ai\\("
    - from: "bae/repl/shell.py"
      to: "self.namespace"
      via: "ai injected as namespace['ai']"
      pattern: "namespace\\[\"ai\"\\]"
---

<objective>
Wire the AI object into CortexShell so NL mode is live and ai is available in the namespace.

Purpose: Replaces the NL mode stub ("NL mode coming in Phase 18") with real AI dispatch. After this plan, `await ai("question")` works from PY mode and typing in NL mode invokes the AI agent. The AI object is created at shell init with lazy Agent construction (no API key needed until first use).

Output: Modified `bae/repl/shell.py` with AI wiring, plus integration tests verifying the wiring.
</objective>

<execution_context>
@/Users/dzaramelcone/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dzaramelcone/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/18-ai-agent/18-RESEARCH.md
@.planning/phases/18-ai-agent/18-01-SUMMARY.md
@bae/repl/shell.py
@bae/repl/ai.py
@bae/lm.py
@tests/repl/test_store_integration.py
@tests/repl/test_namespace_integration.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wire AI into CortexShell</name>
  <files>bae/repl/shell.py</files>
  <action>
Modify `bae/repl/shell.py` to create and wire the AI object. Follow the established pattern from Phase 16 (channels) and Phase 17 (namespace) for object injection.

1. **Add import** at top of file:
   ```python
   from bae.repl.ai import AI
   from bae.lm import PydanticAIBackend
   ```

2. **In `CortexShell.__init__`**, after the router/channels setup and before PromptSession creation:
   ```python
   lm = PydanticAIBackend()
   self.ai = AI(lm=lm, router=self.router, namespace=self.namespace)
   self.namespace["ai"] = self.ai
   ```
   The AI object receives the namespace dict (same reference seed() created), the router (for [ai] channel writes), and a default LM backend. Agent construction is lazy -- no API key check here.

3. **Replace NL mode stub** in `run()`. The current lines 169-171:
   ```python
   elif self.mode == Mode.NL:
       stub = f"(NL mode stub) {text}\nNL mode coming in Phase 18."
       self.router.write("ai", stub, mode="NL")
   ```
   Replace with:
   ```python
   elif self.mode == Mode.NL:
       try:
           await self.ai(text)
       except Exception:
           tb = traceback.format_exc()
           self.router.write("ai", tb.rstrip("\n"), mode="NL", metadata={"type": "error"})
   ```
   The AI.__call__ method handles channel output internally. The shell only handles errors. This matches the PY mode pattern where router.write handles output and the handler only writes error tracebacks.

4. **Do NOT** add any other NL-specific logic (streaming, auto-execution, special prompts). The AI class owns all NL behavior.
  </action>
  <verify>
`python -c "from bae.repl.shell import CortexShell; s = CortexShell(); print(type(s.ai).__name__); print('ai' in s.namespace)"` outputs "AI" and "True".
  </verify>
  <done>
CortexShell creates AI object at init, injects it into namespace as 'ai', and NL mode dispatches to await self.ai(text) with error handling via [ai] channel.
  </done>
</task>

<task type="auto">
  <name>Task 2: Integration tests for AI wiring</name>
  <files>tests/repl/test_ai_integration.py</files>
  <action>
Create `tests/repl/test_ai_integration.py` with integration tests verifying the AI wiring in CortexShell. These tests do NOT call the real LLM API -- they verify the wiring is correct by inspecting the shell object and its namespace.

Follow existing integration test patterns from `tests/repl/test_store_integration.py` and `tests/repl/test_namespace_integration.py`.

Test class: **TestAIIntegration**

1. `test_ai_in_namespace` -- Create CortexShell, verify `"ai" in shell.namespace`, verify `isinstance(shell.namespace["ai"], AI)`.

2. `test_ai_repr_in_namespace` -- Create CortexShell, verify `repr(shell.namespace["ai"])` contains "await ai('question')" and "0 messages".

3. `test_ai_has_router` -- Create CortexShell, verify `shell.ai._router is shell.router` (same router reference).

4. `test_ai_has_namespace` -- Create CortexShell, verify `shell.ai._namespace is shell.namespace` (same namespace reference, so AI sees live namespace state).

5. `test_ai_has_lm` -- Create CortexShell, verify `shell.ai._lm` is a PydanticAIBackend instance.

6. `test_ai_lazy_agent` -- Create CortexShell, verify `shell.ai._agent is None` (no agent created until first call).

7. `test_ai_extract_code_from_namespace` -- Create CortexShell, call `shell.namespace["ai"].extract_code("```python\nx = 1\n```")`, verify returns `["x = 1"]`.

8. `test_nl_stub_removed` -- Inspect the source of `shell.py` (or verify by checking that the NL mode handler no longer contains "Phase 18" string). Can use `import inspect; src = inspect.getsource(CortexShell.run); assert "Phase 18" not in src`.

Import AI from `bae.repl.ai` for isinstance checks. Import CortexShell from `bae.repl.shell`. Import PydanticAIBackend from `bae.lm`.
  </action>
  <verify>
`pytest tests/repl/test_ai_integration.py -v` -- all tests pass. `pytest tests/repl/ -v` -- zero regressions across all repl test files.
  </verify>
  <done>
8 integration tests pass verifying AI wiring: namespace presence, router/namespace reference sharing, lazy agent init, extract_code accessibility, NL stub removal. Zero regressions in existing repl tests.
  </done>
</task>

</tasks>

<verification>
- `pytest tests/repl/ -v` -- all tests pass (existing + new)
- `python -c "from bae.repl.shell import CortexShell; s = CortexShell(); print('ai' in s.namespace)"` prints True
- NL mode stub text "Phase 18" no longer appears in shell.py
</verification>

<success_criteria>
- NL mode dispatches to AI.__call__ instead of stub
- ai object accessible in namespace from PY mode
- Errors in NL mode route to [ai] channel (no REPL crash)
- AI lazy init means no API key needed at shell startup
- 8+ integration tests pass
- Zero regressions in existing repl tests (115+ tests)
</success_criteria>

<output>
After completion, create `.planning/phases/18-ai-agent/18-02-SUMMARY.md`
</output>
