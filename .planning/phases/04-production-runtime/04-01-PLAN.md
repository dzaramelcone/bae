---
phase: 04-production-runtime
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - bae/optimized_lm.py
  - tests/test_optimized_lm.py
autonomous: true

must_haves:
  truths:
    - "OptimizedLM uses pre-loaded predictor when node type exists in optimized dict"
    - "OptimizedLM falls back to fresh predictor when node type missing from optimized dict"
    - "Usage statistics track optimized vs naive predictor calls"
    - "OptimizedLM preserves DSPyBackend retry and error handling behavior"
  artifacts:
    - path: "bae/optimized_lm.py"
      provides: "OptimizedLM class extending DSPyBackend"
      exports: ["OptimizedLM"]
    - path: "tests/test_optimized_lm.py"
      provides: "Tests for OptimizedLM behavior"
      min_lines: 80
  key_links:
    - from: "bae/optimized_lm.py"
      to: "bae/dspy_backend.py"
      via: "class inheritance"
      pattern: "class OptimizedLM\\(DSPyBackend\\)"
    - from: "bae/optimized_lm.py"
      to: "bae/compiler.py"
      via: "node_to_signature import"
      pattern: "from bae.compiler import node_to_signature"
---

<objective>
Create OptimizedLM backend that uses pre-loaded optimized predictors when available, with graceful fallback to naive (fresh) predictors.

Purpose: Enable production graphs to benefit from compiled prompts without requiring all nodes to be optimized. Addresses RUN-01 and RUN-02 requirements.
Output: Working `bae/optimized_lm.py` with full test coverage.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-production-runtime/04-RESEARCH.md

# Existing code to build on
@bae/dspy_backend.py
@bae/compiler.py
@bae/optimizer.py
</context>

<feature>
  <name>OptimizedLM with Predictor Registry and Fallback</name>
  <files>bae/optimized_lm.py, tests/test_optimized_lm.py</files>
  <behavior>
    OptimizedLM extends DSPyBackend to use pre-loaded optimized predictors:

    1. Construction:
       - `OptimizedLM(optimized=None, max_retries=1)`
       - optimized: dict[type[Node], dspy.Predict] or None
       - Initializes stats counter: {"optimized": 0, "naive": 0}

    2. Predictor selection (_get_predictor_for_target):
       - If target in self.optimized: return optimized predictor, increment stats["optimized"]
       - Else: create fresh predictor via node_to_signature, increment stats["naive"]

    3. make() override:
       - Use _get_predictor_for_target instead of creating fresh predictor
       - Preserve all retry and error handling from DSPyBackend

    4. decide() behavior:
       - Inherits from DSPyBackend (no override needed - decide calls make internally)

    5. Observability:
       - get_stats() returns copy of stats dict
       - Optional: debug logging when predictor is selected

    Test cases:
    - test_uses_optimized_predictor_when_available
    - test_falls_back_to_naive_when_not_available
    - test_stats_track_optimized_calls
    - test_stats_track_naive_calls
    - test_mixed_optimized_and_naive_in_same_session
    - test_preserves_retry_behavior_on_parse_error
    - test_empty_optimized_dict_uses_all_naive
  </behavior>
  <implementation>
    Create bae/optimized_lm.py:

    ```python
    """Optimized LM backend using pre-loaded predictors.

    Extends DSPyBackend to use optimized predictors when available,
    falling back to fresh (naive) predictors when not.
    """
    from __future__ import annotations

    import logging
    from typing import TYPE_CHECKING, TypeVar

    import dspy

    from bae.compiler import node_to_signature
    from bae.dspy_backend import DSPyBackend

    if TYPE_CHECKING:
        from bae.node import Node

    T = TypeVar("T", bound="Node")
    logger = logging.getLogger(__name__)


    class OptimizedLM(DSPyBackend):
        """DSPyBackend that uses pre-loaded optimized predictors when available.

        For nodes with optimized predictors in the registry, uses the pre-loaded
        predictor (with few-shot demos from BootstrapFewShot). For nodes without
        optimized versions, falls back to creating fresh predictors (naive prompts).

        Tracks usage statistics for observability.
        """

        def __init__(
            self,
            optimized: dict[type[Node], dspy.Predict] | None = None,
            max_retries: int = 1,
        ):
            """Initialize with optional optimized predictors.

            Args:
                optimized: Dict mapping node classes to their optimized predictors.
                           If None or empty, all calls use naive (fresh) predictors.
                max_retries: Number of retries for parse/API failures (default 1).
            """
            super().__init__(max_retries=max_retries)
            self.optimized = optimized or {}
            self.stats = {"optimized": 0, "naive": 0}

        def _get_predictor_for_target(self, target: type[Node]) -> dspy.Predict:
            """Get predictor for target type, preferring optimized.

            Args:
                target: The target Node type.

            Returns:
                Either the pre-loaded optimized predictor or a fresh one.
            """
            if target in self.optimized:
                self.stats["optimized"] += 1
                logger.debug(f"Using optimized predictor for {target.__name__}")
                return self.optimized[target]

            # Fallback to fresh predictor
            self.stats["naive"] += 1
            logger.debug(f"Using naive predictor for {target.__name__}")
            return dspy.Predict(node_to_signature(target))

        def make(self, node: Node, target: type[T], **deps) -> T:
            """Produce target using optimized predictor if available.

            Overrides DSPyBackend.make() to use pre-loaded predictors from
            the optimized registry when available.

            Args:
                node: The current node providing context.
                target: The target Node type to produce.
                **deps: Additional Dep values to pass as inputs.

            Returns:
                An instance of the target type.

            Raises:
                BaeParseError: If parsing fails after retry.
                BaeLMError: If API fails after retry.
            """
            from bae.exceptions import BaeParseError

            predictor = self._get_predictor_for_target(target)
            inputs = self._build_inputs(node, **deps)

            last_error = None
            for attempt in range(self.max_retries + 1):
                error_hint = str(last_error) if last_error else None

                try:
                    result = self._call_with_retry(predictor, inputs, error_hint)
                    output = result.output
                    return self._parse_output(output, target)
                except ValueError as e:
                    last_error = e
                    if attempt < self.max_retries:
                        continue
                    raise BaeParseError(str(e), cause=e) from e

            raise BaeParseError("Unexpected parse failure", cause=last_error)

        def get_stats(self) -> dict[str, int]:
            """Return usage statistics.

            Returns:
                Dict with counts of "optimized" and "naive" predictor uses.
            """
            return self.stats.copy()
    ```

    Note: decide() does NOT need override - it inherits from DSPyBackend and
    internally calls self.make(), which will use our overridden make().
  </implementation>
</feature>

<verification>
```bash
# Run tests for optimized_lm
cd /Users/dzaramelcone/lab/bae && python -m pytest tests/test_optimized_lm.py -v

# Verify all existing tests still pass
cd /Users/dzaramelcone/lab/bae && python -m pytest tests/ -v --tb=short
```
</verification>

<success_criteria>
- [ ] tests/test_optimized_lm.py exists with 7+ test cases
- [ ] All tests pass (pytest exit code 0)
- [ ] bae/optimized_lm.py exports OptimizedLM class
- [ ] OptimizedLM uses optimized predictor when target in optimized dict
- [ ] OptimizedLM falls back to naive predictor when target not in dict
- [ ] get_stats() returns accurate usage counts
- [ ] Existing tests in test_dspy_backend.py still pass (no regressions)
</success_criteria>

<output>
After completion, create `.planning/phases/04-production-runtime/04-01-SUMMARY.md`
</output>
