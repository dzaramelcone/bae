---
phase: 03-optimization
plan: 02
type: tdd
wave: 2
depends_on: ["03-01"]
files_modified:
  - bae/optimizer.py
  - tests/test_optimizer.py
autonomous: true

must_haves:
  truths:
    - "optimize_node() runs BootstrapFewShot on trainset"
    - "optimize_node() returns optimized dspy.Predict"
    - "optimize_node() skips optimization with <10 examples"
    - "optimize_node() uses node_to_signature for signature generation"
    - "optimize_node() filters trainset to matching node type"
  artifacts:
    - path: "bae/optimizer.py"
      provides: "optimize_node function"
      exports: ["optimize_node"]
    - path: "tests/test_optimizer.py"
      provides: "TDD tests for optimization"
      contains: "test_optimize_node"
  key_links:
    - from: "bae/optimizer.py"
      to: "bae/compiler.py"
      via: "node_to_signature import"
      pattern: "from bae\\.compiler import node_to_signature"
    - from: "bae/optimizer.py"
      to: "dspy.teleprompt"
      via: "BootstrapFewShot import"
      pattern: "BootstrapFewShot"
---

<objective>
TDD: BootstrapFewShot optimization for node predictors

Purpose: optimize_node() takes a node class and training examples, runs BootstrapFewShot to select high-quality demonstrations, and returns an optimized predictor. This implements OPT-02.

Output: optimize_node() function in bae/optimizer.py, fully tested
</objective>

<context>
@.planning/PROJECT.md
@.planning/phases/03-optimization/03-RESEARCH.md
@.planning/phases/03-optimization/03-01-SUMMARY.md

@bae/compiler.py
@bae/node.py
</context>

<feature>
  <name>BootstrapFewShot Optimization</name>
  <files>bae/optimizer.py, tests/test_optimizer.py</files>
  <behavior>
    optimize_node(node_cls: type[Node], trainset: list[dspy.Example], metric: Callable | None = None) -> dspy.Predict:
    - Filters trainset to examples where node_type matches node_cls.__name__
    - If <10 filtered examples: returns unoptimized dspy.Predict(signature)
    - Otherwise: runs BootstrapFewShot with filtered examples
    - Uses node_transition_metric if no metric provided
    - Returns optimized predictor

    BootstrapFewShot config:
    - max_bootstrapped_demos=4 (generated from teacher)
    - max_labeled_demos=8 (from trainset directly)
    - max_rounds=1 (single bootstrap iteration)

    Cases:
    - optimize_node(NodeA, trainset_with_20_NodeA_examples) -> optimized Predict
    - optimize_node(NodeA, trainset_with_5_NodeA_examples) -> unoptimized Predict
    - optimize_node(NodeA, trainset_with_mixed_types) -> filters to NodeA only
    - optimize_node(NodeA, empty_trainset) -> unoptimized Predict
  </behavior>
  <implementation>
    Add to bae/optimizer.py:

    1. Import BootstrapFewShot:
       from dspy.teleprompt import BootstrapFewShot

    2. optimize_node():
       - Filter: node_examples = [ex for ex in trainset if ex.node_type == node_cls.__name__]
       - Early return if len(node_examples) < 10:
         return dspy.Predict(node_to_signature(node_cls))
       - Create student: dspy.Predict(node_to_signature(node_cls))
       - Create optimizer: BootstrapFewShot(metric=metric or node_transition_metric, ...)
       - Return optimizer.compile(student, trainset=node_examples)

    Testing approach:
    - Mock dspy.Predict and BootstrapFewShot to avoid LLM calls
    - Verify correct filtering of trainset
    - Verify early return for small trainsets
    - Verify BootstrapFewShot called with correct params
  </implementation>
</feature>

<verification>
```bash
pytest tests/test_optimizer.py -v -k "optimize"
```

All optimizer tests pass. Coverage includes:
- Small trainset returns unoptimized predictor
- Large trainset runs optimization
- Trainset filtering by node type
- Custom metric support
- Default metric fallback
</verification>

<success_criteria>
- optimize_node() correctly filters trainset by node type
- Returns unoptimized predictor when trainset too small
- Runs BootstrapFewShot when trainset sufficient
- Uses node_to_signature for signature generation
- Satisfies OPT-02
</success_criteria>

<output>
After completion, create `.planning/phases/03-optimization/03-02-SUMMARY.md`
</output>
