---
phase: 29-observability
plan: 04
type: execute
wave: 1
depends_on: []
files_modified:
  - bae/repl/graph_commands.py
  - tests/repl/test_graph_commands.py
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "Graph completion produces exactly one done notification, not two"
    - "Quiet mode suppresses submitted and resolved messages"
  artifacts:
    - path: "bae/repl/graph_commands.py"
      provides: "De-duplicated lifecycle and policy-gated messages"
    - path: "tests/repl/test_graph_commands.py"
      provides: "Tests for single done notification and quiet suppression"
  key_links:
    - from: "bae/repl/graph_commands.py"
      to: "bae/repl/engine.py"
      via: "_on_done only handles cancellation; engine _emit handles complete/fail"
      pattern: "_on_done.*cancel"
---

<objective>
Fix duplicate done notification and policy bypass for submitted/resolved messages.

Purpose: UAT test 1 reported two "done" messages (one in ms, one in seconds). UAT test 2 reported that submitted/resolved messages ignore OutputPolicy in quiet mode. Both bugs are in graph_commands.py.
Output: Single done notification per graph, quiet mode suppresses non-essential messages.
</objective>

<execution_context>
@/Users/dzaramelcone/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dzaramelcone/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/29-observability/29-01-SUMMARY.md
@.planning/phases/29-observability/29-02-SUMMARY.md
@bae/repl/graph_commands.py
@bae/repl/engine.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Remove done/fail duplication from _on_done, gate submitted/resolved by policy</name>
  <files>bae/repl/graph_commands.py</files>
  <action>
Two changes in graph_commands.py:

1. **_attach_done_callback / _on_done (lines 104-127):** The engine already emits "complete" and "fail" events via `_emit()` in `_execute` and `_wrap_coro`. The `_on_done` task callback duplicates these with different formatting (seconds vs ms). Remove the `task.exception()` and success branches from `_on_done`. Keep ONLY the `task.cancelled()` branch because cancellation via `tm.revoke()` raises `CancelledError` which the engine catches and re-raises (no `_emit('cancel')` call exists in engine -- cancel is only `run.state = GraphState.CANCELLED`). The _on_done callback is the only place that writes the cancellation message to the graph channel.

After the fix, `_on_done` should look like:
```python
def _on_done(task, _run=run):
    if task.cancelled():
        shell.router.write(
            "graph", f"{_run.run_id} cancelled", mode="GRAPH",
            metadata={"type": "lifecycle", "event": "cancel", "run_id": _run.run_id},
        )
```

2. **submitted message (lines 97-100):** Gate behind `run.policy.should_emit("start")`. The "submitted" acknowledgment is a lifecycle event equivalent to "start". Wrap the existing `shell.router.write("graph", f"submitted {run.run_id}", ...)` in `if run.policy.should_emit("start"):`.

3. **resolved message (lines 344-349):** Gate behind `run.policy.should_emit("gate")`. The "resolved" acknowledgment is a gate-related event. In `_cmd_input`, wrap the `shell.router.write("graph", f"resolved {gate_id}: ...")` in a policy check. The run must be looked up from the gate's `run_id` via `shell.engine.get(gate.run_id)`. If the run is not found (already archived), show the message unconditionally (safe default).
  </action>
  <verify>uv run pytest tests/repl/test_graph_commands.py -x -q</verify>
  <done>Existing tests pass. _on_done only writes for cancellation. Submitted/resolved messages gated by policy.</done>
</task>

<task type="auto">
  <name>Task 2: Add tests for single done notification and quiet policy suppression</name>
  <files>tests/repl/test_graph_commands.py</files>
  <action>
Add tests to verify the two fixes:

1. **test_done_notification_not_duplicated:** Submit a graph that completes successfully. Collect all messages written to the "graph" channel. Assert that exactly ONE message contains "done" (from the engine _emit, not two). The message should use the engine's ms format (e.g. "g1 done (XXms)").

2. **test_quiet_suppresses_submitted:** Run a graph with `--quiet` flag. Verify no "submitted" message appears in graph channel output.

3. **test_quiet_suppresses_resolved:** If feasible with existing test infrastructure (gate test fixtures), verify that resolving a gate in quiet mode does not produce a "resolved" message. If gate test setup is too heavy, skip this and note in the test file why.

Use the existing test patterns: MockShell / FakeShell fixtures, capturing router.write calls, async test with event loop. Follow the patterns established in the existing test file.
  </action>
  <verify>uv run pytest tests/repl/test_graph_commands.py -x -q</verify>
  <done>New tests pass, proving single done notification and quiet suppression.</done>
</task>

</tasks>

<verification>
- uv run pytest tests/ -x -q --ignore=tests/test_integration.py
- No duplicate "done" messages in test output
- Quiet mode tests prove submitted/resolved suppression
</verification>

<success_criteria>
- Exactly one "done" notification per graph completion (from engine _emit, not _on_done)
- --quiet suppresses "submitted" and "resolved" messages
- All existing tests still pass
</success_criteria>

<output>
After completion, create `.planning/phases/29-observability/29-04-SUMMARY.md`
</output>
