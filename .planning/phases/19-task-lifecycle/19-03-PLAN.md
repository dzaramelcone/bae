---
phase: 19-task-lifecycle
plan: 03
type: execute
wave: 1
depends_on: ["19-02"]
files_modified:
  - bae/repl/shell.py
  - bae/repl/ai.py
  - tests/repl/test_task_lifecycle.py
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "Bottom toolbar remains visible while NL/GRAPH/BASH tasks execute"
    - "Ctrl-C during task execution opens kill menu (prompt_toolkit key binding fires)"
    - "AI task cancellation suppresses response output even when subprocess completes before CancelledError delivery"
  artifacts:
    - path: "bae/repl/shell.py"
      provides: "Background dispatch for tracked modes, sequential PY mode"
      contains: "create_task.*_dispatch_tracked"
    - path: "bae/repl/ai.py"
      provides: "CancelledError guard around response write"
      contains: "CancelledError"
    - path: "tests/repl/test_task_lifecycle.py"
      provides: "Tests for background dispatch and AI cancellation guard"
  key_links:
    - from: "bae/repl/shell.py"
      to: "prompt_toolkit prompt_async"
      via: "prompt_async stays active during task execution for NL/GRAPH/BASH"
      pattern: "prompt_async.*while.*tasks"
    - from: "bae/repl/ai.py"
      to: "router.write"
      via: "CancelledError guard prevents response write after cancellation"
      pattern: "except asyncio.CancelledError"
---

<objective>
Fix two UAT failures: toolbar disappearing during task execution (test 2) and kill menu never appearing on Ctrl-C (test 5).

Purpose: Both failures share the same root cause -- prompt_async() returns before _dispatch() runs, so prompt_toolkit is inactive during task execution. The toolbar erases and key bindings stop firing. Fix by running tracked mode dispatches as background tasks so prompt_async() stays active. Also guard against AI cancellation race condition.

Output: Working toolbar during task execution, working kill menu via Ctrl-C, clean AI cancellation.
</objective>

<execution_context>
@/Users/dzaramelcone/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dzaramelcone/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/STATE.md
@.planning/phases/19-task-lifecycle/19-01-SUMMARY.md
@.planning/phases/19-task-lifecycle/19-02-SUMMARY.md
@.planning/debug/toolbar-disappears.md
@.planning/debug/kill-menu-and-ai-cancel.md
@bae/repl/shell.py
@bae/repl/ai.py
@tests/repl/test_task_lifecycle.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Background dispatch for tracked modes</name>
  <files>bae/repl/shell.py, tests/repl/test_task_lifecycle.py</files>
  <action>
Refactor `run()` and `_dispatch()` in shell.py so that NL, GRAPH, and BASH dispatches run as background tasks while prompt_async() stays active. PY mode remains sequential (synchronous exec, can't cancel).

**Changes to `_dispatch()` in shell.py:**

Split `_dispatch()` into two paths:

1. PY mode: stays inline (awaited directly in run loop). Keep the existing PY branch exactly as-is.

2. NL/GRAPH/BASH modes: extract each into a standalone async helper `_dispatch_tracked(text)` that creates the tracked task, awaits it, and handles CancelledError/Exception. This coroutine is fire-and-forget from `_dispatch()`'s perspective.

Concrete approach -- restructure `_dispatch()`:
- PY mode branch: unchanged, still awaited (sequential).
- NL/GRAPH/BASH branches: instead of `task = self._track_task(coro, name=...); await task`, just do `self._track_task(coro, name=...)` (no await). Remove the `try/except CancelledError` and `try/except Exception` wrappers from these branches inside _dispatch since the task is no longer awaited here. Instead, wrap them with done callbacks or wrap the coroutine itself.

Actually, the cleanest approach: make each tracked mode's coroutine self-contained with its own error handling, so the task can run independently. Do this by wrapping:

```python
async def _run_nl(self, text: str) -> None:
    """NL mode: AI conversation, self-contained error handling."""
    try:
        await self.ai(text)
    except asyncio.CancelledError:
        self.router.write("debug", "cancelled ai task", mode="DEBUG")
    except Exception:
        tb = traceback.format_exc()
        self.router.write("ai", tb.rstrip("\n"), mode="NL", metadata={"type": "error"})

async def _run_graph(self, text: str) -> None:
    """GRAPH mode: graph execution, self-contained error handling."""
    graph = self.namespace.get("graph")
    if not graph:
        self.router.write("graph", "(Graph mode stub) Not yet implemented.", mode="GRAPH")
        return
    try:
        result = await channel_arun(graph, text, self.router)
        if result and result.trace:
            self.namespace["_trace"] = result.trace
    except asyncio.CancelledError:
        self.router.write("debug", "cancelled graph task", mode="DEBUG")
    except Exception as exc:
        trace = getattr(exc, "trace", None)
        if trace:
            self.namespace["_trace"] = trace
        tb = traceback.format_exc()
        self.router.write("graph", tb.rstrip("\n"), mode="GRAPH", metadata={"type": "error"})

async def _run_bash(self, text: str) -> None:
    """BASH mode: shell command, self-contained error handling."""
    try:
        stdout, stderr = await dispatch_bash(text)
    except asyncio.CancelledError:
        self.router.write("debug", "cancelled bash task", mode="DEBUG")
        return
    except Exception:
        tb = traceback.format_exc()
        self.router.write("bash", tb.rstrip("\n"), mode="BASH", metadata={"type": "error"})
        return
    if stdout:
        self.router.write("bash", stdout.rstrip("\n"), mode="BASH")
    if stderr:
        self.router.write("bash", stderr.rstrip("\n"), mode="BASH", metadata={"type": "stderr"})
```

Then simplify `_dispatch()`:
```python
async def _dispatch(self, text: str) -> None:
    """Route input to the active mode handler."""
    if self.mode == Mode.PY:
        # PY mode: sequential (synchronous exec, not cancellable)
        try:
            result, captured = await async_exec(text, self.namespace)
            if captured:
                self.router.write("py", captured.rstrip("\n"), mode="PY", metadata={"type": "stdout"})
            if result is not None:
                output = repr(result)
                self.router.write("py", output, mode="PY", metadata={"type": "expr_result"})
        except KeyboardInterrupt:
            pass
        except Exception:
            tb = traceback.format_exc()
            self.router.write("py", tb.rstrip("\n"), mode="PY", metadata={"type": "error"})
    elif self.mode == Mode.NL:
        self._track_task(self._run_nl(text), name=f"ai:{text[:30]}")
    elif self.mode == Mode.GRAPH:
        self._track_task(self._run_graph(text), name=f"graph:{text[:30]}")
    elif self.mode == Mode.BASH:
        self._track_task(self._run_bash(text), name=f"bash:{text[:30]}")
```

Key insight: `_dispatch()` returns immediately for NL/GRAPH/BASH (fire-and-forget tracked task). Only PY mode blocks.

**Changes to `run()` in shell.py:**

The `run()` loop currently has `await self._dispatch(text)` at line 274 followed by `except KeyboardInterrupt` at line 275. Since _dispatch now returns immediately for tracked modes, the KeyboardInterrupt handler at line 275 is only reachable during PY mode execution. For tracked modes, Ctrl-C fires through the prompt_toolkit key binding (since prompt_async() is active), which already routes to the kill menu.

Keep the `except KeyboardInterrupt` around `_dispatch()` for PY mode — it catches Ctrl-C during synchronous Python execution. No other changes to run().

**Test updates in tests/repl/test_task_lifecycle.py:**

Add tests:

1. `test_dispatch_nl_returns_immediately` — verify that calling _dispatch in NL mode creates a tracked task and returns without awaiting completion. Create shell, set mode to NL, mock self.ai as an AsyncMock that sleeps, call _dispatch, assert it returns immediately (task still in shell.tasks, not yet complete).

2. `test_dispatch_py_blocks` — verify that calling _dispatch in PY mode blocks until completion. Set mode to PY, patch async_exec, call _dispatch, assert async_exec was awaited.

3. `test_dispatch_bash_returns_immediately` — same pattern as NL, verify fire-and-forget for bash mode.
  </action>
  <verify>
Run `python -m pytest tests/repl/test_task_lifecycle.py tests/repl/test_toolbar.py -x -q` — all tests pass including new ones.

Run `python -m pytest tests/ -x -q` — full suite passes (no regressions).
  </verify>
  <done>NL/GRAPH/BASH dispatches are fire-and-forget background tasks. PY mode remains sequential. prompt_async() stays active during tracked task execution so toolbar renders and key bindings fire. Existing _track_task done-callback cleanup still works.</done>
</task>

<task type="auto">
  <name>Task 2: AI cancellation race guard</name>
  <files>bae/repl/ai.py, tests/repl/test_task_lifecycle.py</files>
  <action>
Fix the race condition where AI subprocess completes before CancelledError is delivered, causing response to be written even though the task was cancelled.

**Changes to `AI.__call__()` in ai.py:**

After the `try/except` block around `process.communicate()` (lines 87-97), wrap the response processing (lines 99-106) in a CancelledError guard:

```python
        # Lines 87-97 unchanged (try/except for communicate)

        if process.returncode != 0:
            stderr = stderr_bytes.decode()
            raise RuntimeError(f"AI failed: {stderr}")

        response = stdout_bytes.decode().strip()
        self._call_count += 1
        try:
            self._router.write("ai", response, mode="NL", metadata={"type": "response"})
        except asyncio.CancelledError:
            raise
        return response
```

Wait -- that's not quite right. The CancelledError arrives at the next await point. Since `router.write` is synchronous, there's no await point for CancelledError to fire. The real fix is to check `asyncio.current_task().cancelled()` or to add an explicit `await asyncio.sleep(0)` checkpoint before writing the response, giving the event loop a chance to deliver the pending CancelledError:

```python
        response = stdout_bytes.decode().strip()
        # Yield to event loop: if our task was cancelled while subprocess
        # was completing, the CancelledError is delivered here rather than
        # after we've already written the response.
        await asyncio.sleep(0)
        self._call_count += 1
        self._router.write("ai", response, mode="NL", metadata={"type": "response"})
        return response
```

The `await asyncio.sleep(0)` is the standard asyncio pattern to create a cancellation checkpoint. If the task was cancelled (via task.cancel() from the kill menu or double-Ctrl-C), the pending CancelledError will be raised at this await, which propagates up through the _run_nl wrapper's CancelledError handler. If not cancelled, sleep(0) returns instantly (sub-microsecond).

**Test addition in tests/repl/test_task_lifecycle.py:**

Add test `test_ai_cancellation_checkpoint`:
- Create an AI instance with mocked router and namespace
- Patch `asyncio.create_subprocess_exec` to return a mock process that returns stdout immediately (simulating fast subprocess completion)
- Create a task for ai("test")
- After the subprocess mock returns but before the test awaits the task, call task.cancel()
- Await the task, expect CancelledError
- Assert router.write was NOT called with "response" metadata (the cancellation checkpoint caught it)

Concrete test:
```python
@pytest.mark.asyncio
async def test_ai_cancellation_checkpoint(self):
    """AI response suppressed when task cancelled during subprocess completion race."""
    from bae.repl.ai import AI

    mock_proc = AsyncMock()
    mock_proc.communicate = AsyncMock(return_value=(b"response text", b""))
    mock_proc.returncode = 0

    router = MagicMock()
    ns = {}
    ai = AI(lm=MagicMock(), router=router, namespace=ns)

    with patch("bae.repl.ai.asyncio.create_subprocess_exec", return_value=mock_proc):
        task = asyncio.create_task(ai("test"))
        # Let task run until it hits the sleep(0) checkpoint
        await asyncio.sleep(0)
        task.cancel()
        with pytest.raises(asyncio.CancelledError):
            await task

    # Router.write should NOT have been called with response
    for call in router.write.call_args_list:
        args, kwargs = call
        if len(args) >= 3:
            meta = kwargs.get("metadata", {}) or (args[3] if len(args) > 3 else {})
        else:
            meta = kwargs.get("metadata", {})
        assert meta.get("type") != "response", "Response was written despite cancellation"
```

Note: The exact timing of the test depends on event loop scheduling. The key behavior is that the `await asyncio.sleep(0)` creates a checkpoint where CancelledError can be delivered. If the test is flaky, an alternative assertion is to verify that either CancelledError is raised OR router.write was called (not both simultaneously indicating the race was mitigated). Use the most reliable assertion pattern.
  </action>
  <verify>
Run `python -m pytest tests/repl/test_task_lifecycle.py -x -q` — all tests pass including the new cancellation checkpoint test.

Run `python -m pytest tests/ -x -q` — full suite passes.
  </verify>
  <done>AI.__call__ has an explicit cancellation checkpoint (await asyncio.sleep(0)) before writing response. If the task was cancelled while the subprocess was completing, CancelledError is delivered at the checkpoint instead of after the response is written. Race condition mitigated.</done>
</task>

</tasks>

<verification>
1. `python -m pytest tests/ -x -q` — full test suite passes
2. Manual verification (UAT retest):
   - Launch cortex, run `sleep 10` in BASH mode — toolbar stays visible showing "1 task"
   - Launch cortex, run AI query in NL mode — toolbar stays visible during execution
   - Press Ctrl-C during task execution — kill menu dialog appears
   - Press Ctrl-C twice rapidly — all tasks cancelled
</verification>

<success_criteria>
- Bottom toolbar remains visible during NL/GRAPH/BASH task execution
- Ctrl-C during task execution fires prompt_toolkit key binding (kill menu appears)
- AI response suppressed when task cancelled during subprocess completion race
- All existing tests pass (no regressions)
- PY mode still executes sequentially (no change to synchronous behavior)
</success_criteria>

<output>
After completion, create `.planning/phases/19-task-lifecycle/19-03-SUMMARY.md`
</output>
