---
phase: 32.2-userview-tool-call-stripping
plan: 04
type: execute
wave: 1
depends_on: []
files_modified:
  - bae/repl/spaces/view.py
  - bae/repl/ai.py
  - bae/repl/tools.py
  - tests/repl/test_ai.py
  - tests/test_resource.py
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "Tool calls in <run> blocks display as diamond-bullet one-liners, not full execution panels"
    - "Resource context prefix [source] shown on tool summaries when inside a resource"
    - "Bad tool params return pydantic validation error with signature hint, not raw TypeError"
  artifacts:
    - path: "bae/repl/spaces/view.py"
      provides: "_make_tool_wrapper wrapping raw bound methods with validation"
      contains: "_make_tool_wrapper"
    - path: "bae/repl/ai.py"
      provides: "Tool call detection in <run> block handler emitting tool_translated"
      contains: "_SIMPLE_TOOL_RE"
    - path: "bae/repl/tools.py"
      provides: "_validate_tool_params already exists (no changes needed)"
  key_links:
    - from: "bae/repl/spaces/view.py"
      to: "bae/repl/tools.py"
      via: "_make_tool_wrapper calls _validate_tool_params"
      pattern: "_validate_tool_params"
    - from: "bae/repl/ai.py"
      to: "bae/repl/ai.py::_tool_summary"
      via: "<run> block handler calls _tool_summary for recognized tool calls"
      pattern: "_tool_summary"
---

<objective>
Close 3 UAT gaps where 32.2 features (summaries, validation, resource prefix) were built on the XML tag path but the AI always uses the <run> block path.

Purpose: The AI calls tool callables directly via <run>read("bae")</run>, bypassing ToolRouter.dispatch() and run_tool_calls(). All 32.2 features are on the wrong code path. This plan wires them onto the actual path.

Output: Tool calls via <run> blocks render as diamond-bullet summaries with resource context prefix, and bad params get pydantic validation errors.
</objective>

<execution_context>
@/Users/dzaramelcone/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dzaramelcone/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/debug/tool-summary-wrong-path.md
@.planning/phases/32.2-userview-tool-call-stripping/32.2-01-SUMMARY.md
@.planning/phases/32.2-userview-tool-call-stripping/32.2-03-SUMMARY.md

@bae/repl/ai.py
@bae/repl/spaces/view.py
@bae/repl/tools.py
@bae/repl/views.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wrap namespace callables with validation in _put_tools</name>
  <files>bae/repl/spaces/view.py, bae/repl/tools.py, tests/test_resource.py</files>
  <action>
In `bae/repl/spaces/view.py`, modify `ResourceRegistry._put_tools()` to wrap tool callables with validation before injecting into namespace.

Add a `_make_tool_wrapper` method on `ResourceRegistry`:

```python
def _make_tool_wrapper(self, tool_name: str, method: Callable) -> Callable:
    """Wrap a tool callable with pydantic parameter validation."""
    from bae.repl.tools import _validate_tool_params
    import functools

    @functools.wraps(method)
    def wrapper(*args, **kwargs):
        # Build positional arg as the first param for validation
        sig = inspect.signature(method)
        param_names = [p for p in sig.parameters if p != "self"]
        if args and param_names:
            # Pass raw arg to _validate_tool_params so pydantic can catch type mismatches
            # (e.g., read(325035) should fail validation, not coerce to "325035")
            arg = args[0]
            extra_kwargs = {}
            # Map remaining positional args to param names
            for i, a in enumerate(args[1:], 1):
                if i < len(param_names):
                    extra_kwargs[param_names[i]] = a
            extra_kwargs.update(kwargs)
            validated = _validate_tool_params(tool_name, method, arg, **extra_kwargs)
            if isinstance(validated, str):
                # Validation error -- return the error string
                # (raise ResourceError so the except handler in async_exec catches it cleanly)
                from bae.repl.spaces import ResourceError
                raise ResourceError(validated)
            # Call with validated params
            first_key = param_names[0]
            first_val = validated.pop(first_key)
            return method(first_val, **validated)
        return method(*args, **kwargs)

    return wrapper
```

Update `_put_tools()` to use the wrapper:

```python
def _put_tools(self) -> None:
    if self._namespace is None:
        return
    for name in _TOOL_NAMES:
        self._namespace.pop(name, None)
    current = self.current
    if current is not None:
        for tool_name, method in current.tools().items():
            self._namespace[tool_name] = self._make_tool_wrapper(tool_name, method)
    elif self._home_tools:
        self._namespace.update(self._home_tools)
```

In `tests/test_resource.py`, add tests:
1. Test that wrapped callable validates params -- calling `read(12345)` (int instead of str) raises ResourceError with helpful message containing "parameter error" and signature hint
2. Test that wrapped callable passes through valid params -- calling `read("valid_target")` works normally
3. Test that `_put_tools` injects wrappers not raw methods -- check namespace value is not the raw bound method (use `is not`)

Important: `_validate_tool_params` returns a dict on success or a str on error. The wrapper must check `isinstance(validated, str)` and raise `ResourceError` with that string as the message. Do NOT return the error string -- the AI's `<run>` block `async_exec` expects either a return value or an exception, not a formatted error string as a return value.

Fix rationale: Passing raw `args[0]` (not `str(args[0])`) to `_validate_tool_params` allows pydantic to catch type mismatches. Otherwise `read(325035)` would coerce to `read("325035")` and pass validation, then fail later with the original TypeError.
  </action>
  <verify>
`uv run pytest tests/test_resource.py -x -q` passes. Specifically test that `read(12345)` raises ResourceError with validation message, and `read("valid")` calls through normally.
  </verify>
  <done>Namespace callables go through pydantic validation before execution. Bad params raise ResourceError with helpful message instead of raw TypeError.</done>
</task>

<task type="auto">
  <name>Task 2: Detect tool calls in run-block handler and emit tool_translated</name>
  <files>bae/repl/ai.py, tests/repl/test_ai.py</files>
  <action>
In `bae/repl/ai.py`, modify the `<run>` block handler (the `for code in blocks:` loop, lines ~167-199) to detect when the executed code is a simple tool call and emit `tool_translated` metadata instead of `ai_exec`/`ai_exec_result`.

Add a regex at module level to detect simple tool calls:

```python
_SIMPLE_TOOL_RE = re.compile(r'^(read|write|edit|glob|grep)\((.+)\)$', re.DOTALL)
```

In the `<run>` block loop, AFTER execution completes (after `output` is computed), check if the code matches a simple tool call. If yes, build a synthetic tag and emit `tool_translated` instead of `ai_exec`/`ai_exec_result`:

```python
for code in blocks:
    output = ""
    is_error = False
    try:
        result, captured = await async_exec(code, self._namespace)
        if asyncio.iscoroutine(result):
            buf = StringIO()
            old = sys.stdout
            sys.stdout = buf
            try:
                result = await result
            finally:
                sys.stdout = old
            captured += buf.getvalue()
        output = captured
        if result is not None:
            output += repr(result)
        output = output or "(no output)"
    except (asyncio.CancelledError, KeyboardInterrupt, SystemExit):
        raise
    except BaseException:
        output = traceback.format_exc()
        is_error = True

    # Detect simple tool calls and render as summaries
    tool_m = _SIMPLE_TOOL_RE.match(code.strip())
    if tool_m:
        tool_name = tool_m.group(1)
        tool_arg = tool_m.group(2).strip().strip("'\"")
        tag = f"<{_TOOL_HUMAN_NAMES_REV.get(tool_name, tool_name.title())}:{tool_arg}>"
        # Check if output is an error (ResourceError from validation wrapper or traceback)
        if not is_error:
            is_error = _is_error_output(output)
        summary = _tool_summary(tag, output, is_error=is_error, resource=resource_name)
        self._router.write(
            "py",
            tag,
            mode="PY",
            metadata={
                "type": "tool_translated",
                "label": self._label,
                "tool_summary": summary,
                "is_error": is_error,
            },
        )
    else:
        self._router.write(
            "py", code, mode="PY", metadata={"type": "ai_exec", "label": self._label}
        )
        if output:
            self._router.write(
                "py",
                output,
                mode="PY",
                metadata={"type": "ai_exec_result", "label": self._label},
            )
    outputs.append(output)
```

Add a reverse lookup dict at module level (near the existing `_TOOL_HUMAN_NAMES`):

```python
_TOOL_HUMAN_NAMES_REV = {"read": "R", "write": "W", "edit": "E", "glob": "G", "grep": "Grep"}
```

The tag format must match what `_tool_summary` expects: `<R:arg>`, `<W:arg>`, `<G:pattern>`, `<Grep:pattern>` -- the short form, not `<Read:arg>`.

Handle the `is_error` detection: set `is_error = True` in the except block (already done above). Also check `_is_error_output(output)` for ResourceError strings that come back as normal output (e.g., when the validation wrapper raises ResourceError which gets caught and formatted by `async_exec`'s traceback handler). NOTE: ResourceError from the validation wrapper will appear in the traceback, so `is_error` will already be True from the except clause. But also check with `_is_error_output` as a fallback for edge cases.

In `tests/repl/test_ai.py`, add tests:
1. Test that `_SIMPLE_TOOL_RE` matches `read("bae")`, `glob("*.py")`, `grep("pattern")`, `write("path", "content")`, `edit("path", old="x", new="y")`
2. Test that `_SIMPLE_TOOL_RE` does NOT match `x = read("bae")`, `print(read("bae"))`, `for f in glob("*.py"): print(f)`
3. Test the full `__call__` loop: mock `_send` and `async_exec`. When code is `read("bae")`, verify `router.write` is called with `tool_translated` type and `tool_summary` containing the diamond bullet. Verify it is NOT called with `ai_exec` type.
4. Test that non-tool `<run>` blocks (e.g., `x = 1 + 2`) still emit `ai_exec`/`ai_exec_result` as before.
  </action>
  <verify>
`uv run pytest tests/repl/test_ai.py -x -q` passes. `uv run pytest tests/ -x -q --ignore=tests/test_integration.py` all pass (830+ tests).
  </verify>
  <done>Simple tool calls in run-blocks render as diamond-bullet summaries with resource context prefix. Non-tool run-blocks still render as execution panels.</done>
</task>

</tasks>

<verification>
All three UAT gaps closed:
1. `read("bae")` in a `<run>` block produces `[source] â—† read(bae) -> str (N lines)` summary line, not a full execution panel
2. Resource context prefix `[source]` appears because `resource_name` is already resolved in the eval loop and passed to `_tool_summary`
3. `read(325035)` raises ResourceError with pydantic validation message instead of raw TypeError

Run full test suite: `uv run pytest tests/ -x -q --ignore=tests/test_integration.py`
</verification>

<success_criteria>
- Tool calls via `<run>` blocks emit `tool_translated` metadata with diamond-bullet summary
- Resource context prefix `[source]` shown on summaries when inside a resource
- Bad params (e.g., `read(325035)`) raise ResourceError with signature hint and docstring
- Non-tool `<run>` blocks still render as framed execution panels (no regression)
- All tests pass (830+)
</success_criteria>

<output>
After completion, create `.planning/phases/32.2-userview-tool-call-stripping/32.2-04-SUMMARY.md`
</output>
