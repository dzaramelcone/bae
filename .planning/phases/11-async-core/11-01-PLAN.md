---
phase: 11-async-core
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - bae/lm.py
  - tests/test_lm_protocol.py
  - tests/test_fill_protocol.py
autonomous: true

must_haves:
  truths:
    - "LM Protocol methods (make, decide, choose_type, fill) are declared async"
    - "PydanticAIBackend uses await agent.run() instead of agent.run_sync()"
    - "ClaudeCLIBackend uses asyncio.create_subprocess_exec instead of subprocess.run"
    - "All tests in test_lm_protocol.py and test_fill_protocol.py pass"
  artifacts:
    - path: "bae/lm.py"
      provides: "Async LM Protocol + PydanticAIBackend + ClaudeCLIBackend"
      contains: "async def fill"
    - path: "tests/test_lm_protocol.py"
      provides: "Tests for async LM protocol compliance"
      contains: "async def test_"
    - path: "tests/test_fill_protocol.py"
      provides: "Tests for async fill protocol"
      contains: "async def test_"
  key_links:
    - from: "bae/lm.py"
      to: "pydantic_ai.Agent"
      via: "await agent.run() replaces agent.run_sync()"
      pattern: "await.*agent\\.run\\("
    - from: "bae/lm.py"
      to: "asyncio"
      via: "asyncio.create_subprocess_exec replaces subprocess.run"
      pattern: "asyncio\\.create_subprocess_exec"
---

<objective>
Convert the LM Protocol and both lm.py-resident backends (PydanticAIBackend, ClaudeCLIBackend) from sync to async.

Purpose: The LM Protocol is the foundation of bae's async conversion. All backends must implement async methods before Graph.run() can become async. PydanticAIBackend's native API is already async (agent.run()); we're currently using the sync wrapper (agent.run_sync()). ClaudeCLIBackend uses subprocess.run() which should become asyncio.create_subprocess_exec().

Output: Async LM Protocol, async PydanticAIBackend, async ClaudeCLIBackend, passing tests.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@bae/lm.py
@tests/test_lm_protocol.py
@tests/test_fill_protocol.py

Requirements: ASYNC-02 (LM protocol async), ASYNC-03 (PydanticAI native async), ASYNC-04 (ClaudeCLI async subprocess).

The LM Protocol is a runtime_checkable Protocol with 4 methods: make, decide, choose_type, fill. All must become `async def`.

PydanticAIBackend currently calls `agent.run_sync(prompt)` — change to `await agent.run(prompt)`. PydanticAI's `Agent.run()` is already async-native.

ClaudeCLIBackend currently calls `subprocess.run(cmd, ...)` in `_run_cli_json()` — change to `asyncio.create_subprocess_exec(*cmd, ...)` with `await process.communicate()`. All 4 public methods (make, decide, choose_type, fill) must be `async def` and await `_run_cli_json`.

Fill helpers (_build_fill_prompt, _build_plain_model, validate_plain_fields, _strip_format, _build_choice_schema) stay sync — they're pure computation, no I/O.
</context>

<tasks>

<task type="auto">
  <name>Task 1: Convert lm.py to async</name>
  <files>bae/lm.py</files>
  <action>
  1. Convert LM Protocol methods to async:
     - `async def make(self, node: Node, target: type[T]) -> T`
     - `async def decide(self, node: Node) -> Node | None`
     - `async def choose_type(self, types: list[type[Node]], context: dict[str, object]) -> type[Node]`
     - `async def fill(self, target: type[T], resolved: dict[str, object], instruction: str, source: Node | None = None) -> T`

  2. Convert PydanticAIBackend methods to async:
     - `async def make` — change `agent.run_sync(full_prompt)` to `await agent.run(full_prompt)`
     - `async def decide` — same pattern
     - `async def choose_type` — same pattern
     - `async def fill` — same pattern

  3. Convert ClaudeCLIBackend methods to async:
     - `async def _run_cli_json(self, prompt: str, schema: dict) -> dict | None`:
       - Replace `import subprocess` with `import asyncio`
       - Replace `subprocess.run(cmd, capture_output=True, text=True, timeout=self.timeout)` with:
         ```python
         process = await asyncio.create_subprocess_exec(
             *cmd,
             stdout=asyncio.subprocess.PIPE,
             stderr=asyncio.subprocess.PIPE,
         )
         try:
             stdout_bytes, stderr_bytes = await asyncio.wait_for(
                 process.communicate(), timeout=self.timeout
             )
         except asyncio.TimeoutError:
             process.kill()
             raise RuntimeError(f"Claude CLI timed out after {self.timeout}s")
         stdout = stdout_bytes.decode()
         stderr = stderr_bytes.decode()
         ```
       - Replace `result.returncode` with `process.returncode`
       - Replace `result.stdout` with `stdout`
       - Replace `result.stderr` with `stderr`
     - `async def make` — await `self._run_cli_json()`
     - `async def decide` — await `self._run_cli_json()` and `await self.make()`
     - `async def choose_type` — await `self._run_cli_json()`
     - `async def fill` — await `self._run_cli_json()`

  4. Do NOT change fill helpers (_build_fill_prompt, _build_plain_model, validate_plain_fields, _strip_format, _build_choice_schema, _get_base_type) — they remain sync.

  5. Add `import asyncio` at the top of the file (needed for ClaudeCLIBackend).
  </action>
  <verify>
  `uv run python -c "import bae.lm; import inspect; assert inspect.iscoroutinefunction(bae.lm.PydanticAIBackend.fill)"`
  `uv run python -c "import bae.lm; import inspect; assert inspect.iscoroutinefunction(bae.lm.ClaudeCLIBackend.fill)"`
  </verify>
  <done>
  LM Protocol declares 4 async methods. PydanticAIBackend uses await agent.run(). ClaudeCLIBackend uses asyncio.create_subprocess_exec(). All fill helpers remain sync. File imports cleanly.
  </done>
</task>

<task type="auto">
  <name>Task 2: Migrate test_lm_protocol.py and test_fill_protocol.py to async</name>
  <files>tests/test_lm_protocol.py, tests/test_fill_protocol.py</files>
  <action>
  With `asyncio_mode = "auto"` in pyproject.toml, pytest-asyncio auto-wraps async test functions. The conversion is mechanical:

  1. In test_lm_protocol.py:
     - Find all MockLM / mock backend classes. Make their LM-protocol methods async:
       `async def make(...)`, `async def decide(...)`, `async def choose_type(...)`, `async def fill(...)`
     - Find all `def test_*` functions that call backend methods (make, decide, choose_type, fill).
       Convert to `async def test_*` and add `await` before each backend method call.
     - Tests that only inspect Protocol shape (hasattr, isinstance checks) stay sync.
     - Any test using unittest.mock.patch on backend methods: ensure mock return values work with await. Use `AsyncMock` from `unittest.mock` where mocks are called as coroutines, or make mock functions async explicitly.

  2. In test_fill_protocol.py:
     - Same pattern: async mock backends, async test functions, await calls.
     - Tests that call `graph.run()` need `await graph.run()` — but Graph.run is NOT async yet (that's Plan 03). These tests will need to be deferred or temporarily adjusted.
     - IMPORTANT: If test_fill_protocol.py calls graph.run(), leave those specific tests temporarily with a `# TODO: await after Graph.run async (Plan 03)` comment, or wrap in `asyncio.run()` as a temporary bridge. Actually, the better approach: since Graph.run calls LM methods which are now async, graph.run itself MUST be async to call them. But Graph.run isn't converted yet in Plan 01.
     - RESOLUTION: Tests that call graph.run() AND backend.fill() in the same test should be skipped with `@pytest.mark.skip(reason="Requires async Graph.run - Plan 03")` and re-enabled in Plan 03. Tests that call backend.fill() directly (no graph.run) can be fully converted now.

  3. Do NOT change tests in test_fill_helpers.py — those test sync functions (_build_plain_model, validate_plain_fields) and don't need async.
  </action>
  <verify>
  Run only the converted test files:
  `uv run python -m pytest tests/test_lm_protocol.py tests/test_fill_protocol.py -v --tb=short`
  All tests pass (except any explicitly skipped for Graph.run dependency).
  </verify>
  <done>
  test_lm_protocol.py and test_fill_protocol.py use async test functions with await. MockLM classes have async methods. Tests pass. Any graph.run()-dependent tests are marked skip with clear reason.
  </done>
</task>

</tasks>

<verification>
1. `uv run python -c "import bae.lm"` — imports without error
2. `uv run python -c "import inspect; from bae.lm import LM, PydanticAIBackend, ClaudeCLIBackend; assert all(inspect.iscoroutinefunction(getattr(PydanticAIBackend, m)) for m in ('make', 'decide', 'choose_type', 'fill'))"` — all PydanticAI methods are coroutines
3. `uv run python -c "import inspect; from bae.lm import ClaudeCLIBackend; assert inspect.iscoroutinefunction(ClaudeCLIBackend._run_cli_json)"` — CLI backend subprocess wrapper is async
4. `uv run python -m pytest tests/test_lm_protocol.py tests/test_fill_protocol.py -v` — all tests pass
5. `uv run python -m pytest tests/test_fill_helpers.py -v` — fill helper tests still pass (unmodified, sync)
</verification>

<success_criteria>
- LM Protocol has 4 async method signatures
- PydanticAIBackend.fill/make/decide/choose_type use `await agent.run()`
- ClaudeCLIBackend._run_cli_json uses `asyncio.create_subprocess_exec`
- test_lm_protocol.py and test_fill_protocol.py pass
- test_fill_helpers.py passes unchanged
</success_criteria>

<output>
After completion, create `.planning/phases/11-async-core/11-01-SUMMARY.md`
</output>
